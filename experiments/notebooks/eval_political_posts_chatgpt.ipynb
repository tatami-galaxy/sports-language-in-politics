{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c89a99-f987-417e-8732-9c85fbb87f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import statistics\n",
    "import re\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0430a8-2b90-4c71-8587-4fae03cbb031",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e81619-a047-4a8f-9864-b4f0cebc93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/PortableSSD/CSS/data/processed/'\n",
    "#data_dir = '/users/ujan/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68907815-90ac-424a-8436-2308e22f4ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>created_utc</th><th>subreddit</th><th>category</th><th>super_category</th><th>author</th><th>domain</th><th>url</th><th>title</th><th>selftext</th><th>num_comments</th><th>score</th><th>gilded</th><th>upvote_ratio</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;589v04&quot;</td><td>1476878103</td><td>&quot;The_Donald&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;gmousasi&quot;</td><td>&quot;i.redd.it&quot;</td><td>&quot;https://i.redd…</td><td>&quot;Just a rare ba…</td><td>&quot;&quot;</td><td>17</td><td>1242</td><td>0</td><td>100.0</td></tr><tr><td>&quot;589ygu&quot;</td><td>1476879588</td><td>&quot;Enough_Sanders…</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;12-juin-3049&quot;</td><td>&quot;reddit.com&quot;</td><td>&quot;http://www.red…</td><td>&quot;Bernout gets e…</td><td>&quot;&quot;</td><td>12</td><td>28</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58a7z5&quot;</td><td>1476883248</td><td>&quot;EnoughTrumpSpa…</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;TheIronTARDIS&quot;</td><td>&quot;np.reddit.com&quot;</td><td>&quot;http://np.redd…</td><td>&quot;In case you ne…</td><td>&quot;&quot;</td><td>38</td><td>371</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58aa2h&quot;</td><td>1476883994</td><td>&quot;politics&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;Naggers123&quot;</td><td>&quot;breitbart.com&quot;</td><td>&quot;http://www.bre…</td><td>&quot;Poll: Hillary …</td><td>&quot;&quot;</td><td>170</td><td>305</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58bnuv&quot;</td><td>1476899246</td><td>&quot;politics&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;Metaprinter&quot;</td><td>&quot;gop.com&quot;</td><td>&quot;https://gop.co…</td><td>&quot;Trump asking t…</td><td>&quot;&quot;</td><td>38</td><td>24</td><td>0</td><td>100.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬───────┬────────┬────────────┐\n",
       "│ id     ┆ created_utc ┆ subreddit   ┆ category    ┆ … ┆ num_comment ┆ score ┆ gilded ┆ upvote_rat │\n",
       "│ ---    ┆ ---         ┆ ---         ┆ ---         ┆   ┆ s           ┆ ---   ┆ ---    ┆ io         │\n",
       "│ str    ┆ i64         ┆ str         ┆ str         ┆   ┆ ---         ┆ i64   ┆ i64    ┆ ---        │\n",
       "│        ┆             ┆             ┆             ┆   ┆ i64         ┆       ┆        ┆ f64        │\n",
       "╞════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪═══════╪════════╪════════════╡\n",
       "│ 589v04 ┆ 1476878103  ┆ The_Donald  ┆ politics_20 ┆ … ┆ 17          ┆ 1242  ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 589ygu ┆ 1476879588  ┆ Enough_Sand ┆ politics_20 ┆ … ┆ 12          ┆ 28    ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆ ers_Spam    ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58a7z5 ┆ 1476883248  ┆ EnoughTrump ┆ politics_20 ┆ … ┆ 38          ┆ 371   ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆ Spam        ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58aa2h ┆ 1476883994  ┆ politics    ┆ politics_20 ┆ … ┆ 170         ┆ 305   ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58bnuv ┆ 1476899246  ┆ politics    ┆ politics_20 ┆ … ┆ 38          ┆ 24    ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "└────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴───────┴────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pl.read_csv(data_dir+'posts_2015-21_ps_min_2c_politics.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6419ca-b357-48a6-b588-da9a7157b6ad",
   "metadata": {},
   "source": [
    "##### save positive posts to csv from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d720b85-1c06-4e91-ba43-563ab4c7c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'posts': [], 'exps': []}\n",
    "\n",
    "with open(data_dir+'gpt3_pos_sample.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == 'p':\n",
    "            post = line.split('post : ')[-1].split('\\n')[0]\n",
    "            data_dict['posts'].append(post)\n",
    "        elif line[0] == 'm':\n",
    "            exp = line.split('meta : ')[-1].split('\\n')[0]\n",
    "            data_dict['exps'].append(exp)\n",
    "\n",
    "pos_df = pl.from_dict(data_dict)\n",
    "pos_df.write_csv(data_dir+'gpt3_pos_sample.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021306a-66af-4c64-af06-55fa0ffc66fb",
   "metadata": {},
   "source": [
    "##### save negative posts to csv from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab67bc47-cda3-43d3-8114-c7b1693ff8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'posts': []}\n",
    "\n",
    "with open(data_dir+'gpt3_neg_sample.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == 'p':\n",
    "            post = line.split('post : ')[-1].split('\\n')[0]\n",
    "            data_dict['posts'].append(post)\n",
    "\n",
    "neg_df = pl.from_dict(data_dict)\n",
    "neg_df.write_csv(data_dir+'gpt3_neg_sample.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fefc7-2649-4b04-8d0e-31fe36882a6d",
   "metadata": {},
   "source": [
    "##### store 402 samples into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126fa34d-1526-4dba-ad50-7d9e1a42d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = data_df.filter(pl.col('title').is_in(posts)).unique(subset=[\"title\"]).select([\"id\", \"title\"])\n",
    "\n",
    "samples_df.write_csv(data_dir+'chatgpt_samples.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baa50b-b229-4c1d-8541-3c6cd6386c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5c9f85-a8aa-4f36-a4b0-b8db1c7b65fb",
   "metadata": {},
   "source": [
    "##### chatgpt to find metaphors on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91615661-09ad-4167-853e-6494cbbbcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt3.5 client\n",
    "client = OpenAI(api_key=\"api_key\")  # \"api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14801993-b74b-4417-bf15-cc172dabfa4c",
   "metadata": {},
   "source": [
    "#### Temperature = 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b21714-8092-4e9e-b66c-70258b1a8a4d",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf988fb3-a6ab-490b-a791-0c74a7f13aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3d55f639664cf8852fc069dbc6cea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d476545-88e0-4676-b774-05a96b82af9f",
   "metadata": {},
   "source": [
    "##### store responses and manually add gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07a7b652-8e9c-4498-bc80-4968374980c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df.write_csv(data_dir+'gpt3_responses.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d8a63-d4ea-48a1-bace-de92e162ef32",
   "metadata": {},
   "source": [
    "##### load responses with gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c35eaa3-eb2e-498c-b725-5cb8efe79691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>contains_sports_metaphor</th><th>sports_meta</th><th>explanation</th><th>ground_truth</th><th>post</th></tr><tr><td>str</td><td>bool</td><td>str</td><td>str</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;6ndhz6&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Surprise! Wome…</td></tr><tr><td>&quot;5zopk8&quot;</td><td>true</td><td>&quot;flex its muscl…</td><td>&quot;Assert authori…</td><td>true</td><td>&quot;Graham: Congre…</td></tr><tr><td>&quot;6a8vgu&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Trump Removes …</td></tr><tr><td>&quot;8vllco&quot;</td><td>true</td><td>&quot;set his sights…</td><td>&quot;Targeting or f…</td><td>true</td><td>&quot;Fired FBI Dire…</td></tr><tr><td>&quot;e6nbyn&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Done deal: Cal…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────┬──────────────────┬──────────────────┬──────────────────┬──────────────┬─────────────────┐\n",
       "│ id     ┆ contains_sports_ ┆ sports_meta      ┆ explanation      ┆ ground_truth ┆ post            │\n",
       "│ ---    ┆ metaphor         ┆ ---              ┆ ---              ┆ ---          ┆ ---             │\n",
       "│ str    ┆ ---              ┆ str              ┆ str              ┆ bool         ┆ str             │\n",
       "│        ┆ bool             ┆                  ┆                  ┆              ┆                 │\n",
       "╞════════╪══════════════════╪══════════════════╪══════════════════╪══════════════╪═════════════════╡\n",
       "│ 6ndhz6 ┆ false            ┆ null             ┆ null             ┆ false        ┆ Surprise!       │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Women's         │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Marchers Hired… │\n",
       "│ 5zopk8 ┆ true             ┆ flex its muscle  ┆ Assert authority ┆ true         ┆ Graham:         │\n",
       "│        ┆                  ┆                  ┆ or power         ┆              ┆ Congress to     │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ ‘flex its mu…   │\n",
       "│ 6a8vgu ┆ false            ┆ null             ┆ null             ┆ false        ┆ Trump Removes   │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ FBI Director    │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ James…          │\n",
       "│ 8vllco ┆ true             ┆ set his sights   ┆ Targeting or     ┆ true         ┆ Fired FBI       │\n",
       "│        ┆                  ┆ on               ┆ focusing on a    ┆              ┆ Director James  │\n",
       "│        ┆                  ┆                  ┆ speci…           ┆              ┆ Comey s…        │\n",
       "│ e6nbyn ┆ false            ┆ null             ┆ null             ┆ false        ┆ Done deal:      │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Calgary         │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ taxpayers are…  │\n",
       "└────────┴──────────────────┴──────────────────┴──────────────────┴──────────────┴─────────────────┘"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "responses_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a784f5-8b22-4075-b3b6-353ffd4d75cb",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5b6b0-9ad5-4ca7-ab9f-35cd5da8d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()\n",
    "gt = responses_df['ground_truth'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ab66b-fea5-4754-bc8b-16317ae36e98",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b50203d2-609a-44be-90cf-829bc86210cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 170\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ba574-1a66-402f-9b3a-2c51c868dfc3",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13a00bb4-d4b7-4aeb-9f2c-f0cae4720e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 51\n",
      "fp rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28de756-0074-4d08-abf8-79cd63c82c5b",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10904b9d-89f6-45e0-ae16-99e94ac6a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 27\n",
      "fn rate: 0.11688311688311688\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0e48c-c480-4807-820e-c467eb93fcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65d4c20-ade9-4fa2-b729-b9502e5ebf9a",
   "metadata": {},
   "source": [
    "#### Temperature = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e665ef-f777-4cdb-ad8f-2db30375147b",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6e4bfd1-2092-4f8e-87cb-76a409831c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a8249eadfd4b43a042e788b8741c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.50\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895fe98-9629-4ea8-939d-aa6d4d7602c9",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20fa3d0e-2e51-449b-ba20-0b71fb0b9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423079a3-2bc9-479b-9d0c-b692394eb79a",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36d27d02-3639-487b-8553-e18d5443ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39213-0222-4a1e-96ef-1d79893ae4af",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c8e67b26-c53a-41dc-bcbe-26d725b9e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561a859-94f2-4cf8-b0d3-2577b910e41a",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c98e787b-41b7-49c8-9a4f-dfcff435b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 168\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbe06c-feee-4c1d-b578-6c0fb2fda8c8",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69c13748-5f4b-413a-851c-b975fb1c23e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 53\n",
      "fp rate: 0.31547619047619047\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f58f1-a30d-4a17-929f-eb82138c685f",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89cd46c6-93d0-4656-9d85-394b7cca21ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 31\n",
      "fn rate: 0.13304721030042918\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d82fb-d21d-49f5-86e7-e91ac77ed7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a3e752-4e70-48c2-a64b-7f8dfdf21072",
   "metadata": {},
   "source": [
    "#### Temperature = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fd5e0-3261-4223-82f8-fec97b843497",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52a62d14-7173-4da7-a106-29d421f1efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e597c52aae34c97a6a9587a9939cef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.45\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ee191-ab3b-4e55-8779-5532ef404227",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "238aaf82-3d60-4cab-b834-0e459a1788a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efeb86-1af4-4dfc-a43f-8df70d745ca7",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51ac4244-e47e-41f4-9edd-693b9d53cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef5e16-eba6-429c-a49f-678ec4fe2443",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2ee33c3-a0db-4177-b161-e1f0613786db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbbfa6-7ab6-4174-86f1-55e66606975e",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e447b87-ace2-4bbe-bccc-3ea9d802bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 170\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d4ad5-17f9-4073-a001-582e56bfd65b",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9cb013c1-9b29-45a9-8b15-ff2e0174ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 51\n",
      "fp rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af957694-e266-4a30-8310-c7ded497f3c2",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ba2904ee-d3b9-4acd-97d4-90c2333c627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 27\n",
      "fn rate: 0.11688311688311688\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec5b95-eec9-4c56-9f16-6ccc702d02e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de85b16e-a921-4036-8492-595ff67f6271",
   "metadata": {},
   "source": [
    "#### Temperature = 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7642cd95-1510-43d3-acf4-76c7526e1163",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a6708bd-ec16-440b-b0a7-7657d70ceedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cb6caaad1d401da77ff47201070315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.60\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2980a47-14cc-457b-90d6-f48b8d166dcb",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b7837a2-3d0a-4e14-b554-572be932984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6917ea9-00d6-49d1-b24d-984a9c496fdb",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9abcf77d-b368-420e-9d52-c01dd21622fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720743f-a1e5-47d7-b108-1adc07ff1a12",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4ba35751-7a4a-4fd0-aa34-7551c2eefc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190287bc-80d6-46bf-ae8d-7e110f47d787",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "29892b75-3e3b-4de2-b8cc-cf333bdf2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 177\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f69ac5-9401-4473-aae4-6d8ca976d3e7",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a69ef005-2a51-4e18-8c04-0d02e5dbac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 56\n",
      "fp rate: 0.3163841807909605\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc3a04-19b0-4803-ada7-1d7b924135b9",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "218f80f2-0458-4ac6-8234-27a0d27e132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 25\n",
      "fn rate: 0.11160714285714286\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee63c2f-16f8-4f6b-83bf-a61635786413",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "07c8bf15-d190-486f-b632-00b6e22a5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_6.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a648b-4c10-4f22-b989-d7bc21582b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2862324c-293c-4d1b-9e27-190200fc9a20",
   "metadata": {},
   "source": [
    "#### New prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b81b6e1-f26b-47cc-9e03-ebdb55f6ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5f9d94d3814cdaad015e6f81b6c943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Do not identify sports related words or phrases used in the literal sense as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150b3c9-c08e-4b3d-8e4b-4a17a69cc998",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ea8c5b-7cc1-48ad-823c-a6d2b95c46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24820931-df3f-435c-9e78-07b38cdcdb6a",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fd24f9-5eed-438f-a194-bb0cd27ea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d828ee-c9dc-41bb-b44c-9c31bd145886",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12c7e20-a569-4665-9196-089b26b7b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 147\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e209343-61c2-4945-8e15-bf0f090e2c04",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f4ef631-c9f6-4ebd-bd1e-d16069eca6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 40\n",
      "fp rate: 0.272108843537415\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c20ef-f0f3-40f9-9968-f9bde58f30ee",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd5071b7-2ca3-4dc2-85c5-75cfb668256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 39\n",
      "fn rate: 0.15354330708661418\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832df7e-fd64-48f3-ae57-06cbe5cdd8b9",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5645a25-fc8e-4237-8d89-323ce20009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_new_prompt.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6d366-f07a-4673-87b4-429c6e5b508b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eddf8b1f-0a21-4384-a841-d576a97b9248",
   "metadata": {},
   "source": [
    "#### sports related prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31963e25-0794-43ac-9ddd-afb69f23b744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86a0cf1ef504bca978cdc2f0ef0e278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports or sports related metaphor or not. Do not identify sports related words or phrases used in the literal sense as sports metaphors. If the text does contain a sports or sports related metaphor, identify the sports or sports related metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c58b9-40dc-4124-a2d8-c37be2c8fd6d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a6c89a-78f0-4d2f-bc1f-8f289fd7def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed155c-6873-4d9b-b28d-64040ae26354",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc572def-85ae-423e-bc4f-22df23eff5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4baa9-8ff4-4f3d-8061-5d5e2448c159",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2adad5d-e5fd-42b4-b8c2-c1b484c38073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 119\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e33ef3e-e4ef-4737-a9c4-3db24ce7426e",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0043eac-0bc3-4b35-835d-2c1b61347faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 31\n",
      "fp rate: 0.2605042016806723\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed8f61-d065-4fe7-bb24-e251ec1c29d0",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94d10744-1f8f-4515-acb0-062762ec5f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 58\n",
      "fn rate: 0.20567375886524822\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ac8d0-7fef-498b-95c8-2d4c6258c0a5",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fc40ae5-0ee9-4987-a063-32ed6474f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_sports_rel_prompt.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20327da7-479f-4f32-b49e-c32817119858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the post contains a sports metaphor or not.\n",
    "# Do not identify sports related words or phrases used in the literal sense as sports metaphors.\n",
    "# If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e75839-faeb-4902-ae88-245e787c124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 2\n",
    "\n",
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the post contains a sports metaphor or not.\n",
    "# If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3ab67-c10b-4620-8292-8cc1ad469cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 3\n",
    "\n",
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the title is framed using sports language or not.\n",
    "# If the title is framed using sports language, identify the title and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_language (true/false), explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af7906-d876-45d2-8895-78a1fd96f292",
   "metadata": {},
   "source": [
    "#### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0ac978-4418-4fd4-aeed-4f56b8a4c843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b4b0468eb474ca3ec299c7a16e14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title. Identify if the post contains a sports metaphor or not. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e384d-6e85-445c-b7e8-13fd61ebb5ab",
   "metadata": {},
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be11ef9f-69e0-4db7-98b3-1dbd589be252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbf6d8-47de-401c-9f0e-db33abd8ab05",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00df4eb9-0774-47f3-9ac8-8fbd53249310",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc200bf7-a5ae-4a7f-8cb9-88e1e8eed43d",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphor by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0b7596-0b55-44b7-a6ba-c60bf9e7d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 155\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3850e8a-eb64-4d3d-b435-056aa89276b3",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd3d234-5886-42cd-8b40-810d5e4be816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 45\n",
      "fp rate: 0.2903225806451613\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2828ef-a711-4a8b-8552-98074326be2f",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764cee1a-91f3-41b1-9cab-7cfe88c90e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 36\n",
      "fn rate: 0.14634146341463414\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82125e-a13f-4e18-9bbe-87c671aed85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d71d8b-e2ed-4637-a51a-7cbce1970bc3",
   "metadata": {},
   "source": [
    "#### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f55077-7d35-4a8b-b8a1-5b142485b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458ece7cae94c7b8b54c446f1624f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title. Identify if the title is framed using sports language or not. If the title is framed using sports language, identify the title and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_language (true/false), explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb572f-9f9c-4459-b8ed-20fecdf6c6d9",
   "metadata": {},
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c9ad27-83ce-4ae5-9555-a1e5a486ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_language': [r['contains_sports_language'] for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d385e-c1b6-49f5-8c22-1c624e921e70",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26503e37-1553-46d3-b4c3-1537591cb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_language'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa2dee-0e7c-400e-ba3c-a99f8a9223f7",
   "metadata": {},
   "source": [
    "##### total posts marked as sports language by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a62a30d-af11-4f16-a881-5ad58519b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 21\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4dff5-6019-4c14-939c-c769fb06a5bf",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac040c5-38fa-46cc-9285-b5c76a708da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 10\n",
      "fp rate: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebbbe6-728e-454e-af1d-2f712bfd2ed9",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f15e3d73-a90e-4f9d-8fb3-95aaf0c599bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 135\n",
      "fn rate: 0.35526315789473684\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660720c1-8ce8-4c03-a2eb-0f652d7cabc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
