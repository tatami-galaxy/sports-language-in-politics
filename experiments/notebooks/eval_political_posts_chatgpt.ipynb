{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c89a99-f987-417e-8732-9c85fbb87f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import statistics\n",
    "import re\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0430a8-2b90-4c71-8587-4fae03cbb031",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e81619-a047-4a8f-9864-b4f0cebc93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/PortableSSD/CSS/data/processed/'\n",
    "#data_dir = '/users/ujan/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1de3c6-a98a-40b7-bace-57377f4b95f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68907815-90ac-424a-8436-2308e22f4ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>created_utc</th><th>subreddit</th><th>category</th><th>super_category</th><th>author</th><th>domain</th><th>url</th><th>title</th><th>selftext</th><th>num_comments</th><th>score</th><th>gilded</th><th>upvote_ratio</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;589v04&quot;</td><td>1476878103</td><td>&quot;The_Donald&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;gmousasi&quot;</td><td>&quot;i.redd.it&quot;</td><td>&quot;https://i.redd…</td><td>&quot;Just a rare ba…</td><td>&quot;&quot;</td><td>17</td><td>1242</td><td>0</td><td>100.0</td></tr><tr><td>&quot;589ygu&quot;</td><td>1476879588</td><td>&quot;Enough_Sanders…</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;12-juin-3049&quot;</td><td>&quot;reddit.com&quot;</td><td>&quot;http://www.red…</td><td>&quot;Bernout gets e…</td><td>&quot;&quot;</td><td>12</td><td>28</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58a7z5&quot;</td><td>1476883248</td><td>&quot;EnoughTrumpSpa…</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;TheIronTARDIS&quot;</td><td>&quot;np.reddit.com&quot;</td><td>&quot;http://np.redd…</td><td>&quot;In case you ne…</td><td>&quot;&quot;</td><td>38</td><td>371</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58aa2h&quot;</td><td>1476883994</td><td>&quot;politics&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;Naggers123&quot;</td><td>&quot;breitbart.com&quot;</td><td>&quot;http://www.bre…</td><td>&quot;Poll: Hillary …</td><td>&quot;&quot;</td><td>170</td><td>305</td><td>0</td><td>100.0</td></tr><tr><td>&quot;58bnuv&quot;</td><td>1476899246</td><td>&quot;politics&quot;</td><td>&quot;politics_2019&quot;</td><td>&quot;politics&quot;</td><td>&quot;Metaprinter&quot;</td><td>&quot;gop.com&quot;</td><td>&quot;https://gop.co…</td><td>&quot;Trump asking t…</td><td>&quot;&quot;</td><td>38</td><td>24</td><td>0</td><td>100.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌────────┬─────────────┬─────────────┬─────────────┬───┬─────────────┬───────┬────────┬────────────┐\n",
       "│ id     ┆ created_utc ┆ subreddit   ┆ category    ┆ … ┆ num_comment ┆ score ┆ gilded ┆ upvote_rat │\n",
       "│ ---    ┆ ---         ┆ ---         ┆ ---         ┆   ┆ s           ┆ ---   ┆ ---    ┆ io         │\n",
       "│ str    ┆ i64         ┆ str         ┆ str         ┆   ┆ ---         ┆ i64   ┆ i64    ┆ ---        │\n",
       "│        ┆             ┆             ┆             ┆   ┆ i64         ┆       ┆        ┆ f64        │\n",
       "╞════════╪═════════════╪═════════════╪═════════════╪═══╪═════════════╪═══════╪════════╪════════════╡\n",
       "│ 589v04 ┆ 1476878103  ┆ The_Donald  ┆ politics_20 ┆ … ┆ 17          ┆ 1242  ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 589ygu ┆ 1476879588  ┆ Enough_Sand ┆ politics_20 ┆ … ┆ 12          ┆ 28    ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆ ers_Spam    ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58a7z5 ┆ 1476883248  ┆ EnoughTrump ┆ politics_20 ┆ … ┆ 38          ┆ 371   ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆ Spam        ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58aa2h ┆ 1476883994  ┆ politics    ┆ politics_20 ┆ … ┆ 170         ┆ 305   ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "│ 58bnuv ┆ 1476899246  ┆ politics    ┆ politics_20 ┆ … ┆ 38          ┆ 24    ┆ 0      ┆ 100.0      │\n",
       "│        ┆             ┆             ┆ 19          ┆   ┆             ┆       ┆        ┆            │\n",
       "└────────┴─────────────┴─────────────┴─────────────┴───┴─────────────┴───────┴────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pl.read_csv(data_dir+'posts_2015-21_ps_min_2c_politics.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6419ca-b357-48a6-b588-da9a7157b6ad",
   "metadata": {},
   "source": [
    "##### save positive posts to csv from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d720b85-1c06-4e91-ba43-563ab4c7c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'posts': [], 'exps': []}\n",
    "\n",
    "with open(data_dir+'gpt3_pos_sample.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == 'p':\n",
    "            post = line.split('post : ')[-1].split('\\n')[0]\n",
    "            data_dict['posts'].append(post)\n",
    "        elif line[0] == 'm':\n",
    "            exp = line.split('meta : ')[-1].split('\\n')[0]\n",
    "            data_dict['exps'].append(exp)\n",
    "\n",
    "pos_df = pl.from_dict(data_dict)\n",
    "pos_df.write_csv(data_dir+'gpt3_pos_sample.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021306a-66af-4c64-af06-55fa0ffc66fb",
   "metadata": {},
   "source": [
    "##### save negative posts to csv from the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab67bc47-cda3-43d3-8114-c7b1693ff8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'posts': []}\n",
    "\n",
    "with open(data_dir+'gpt3_neg_sample.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        if line[0] == 'p':\n",
    "            post = line.split('post : ')[-1].split('\\n')[0]\n",
    "            data_dict['posts'].append(post)\n",
    "\n",
    "neg_df = pl.from_dict(data_dict)\n",
    "neg_df.write_csv(data_dir+'gpt3_neg_sample.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fefc7-2649-4b04-8d0e-31fe36882a6d",
   "metadata": {},
   "source": [
    "##### store 402 samples into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126fa34d-1526-4dba-ad50-7d9e1a42d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = data_df.filter(pl.col('title').is_in(posts)).unique(subset=[\"title\"]).select([\"id\", \"title\"])\n",
    "\n",
    "samples_df.write_csv(data_dir+'chatgpt_samples.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60baa50b-b229-4c1d-8541-3c6cd6386c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb5c9f85-a8aa-4f36-a4b0-b8db1c7b65fb",
   "metadata": {},
   "source": [
    "##### chatgpt to find metaphors on the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91615661-09ad-4167-853e-6494cbbbcaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt3.5 client\n",
    "client = OpenAI(api_key=\"api_key\")  # \"api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14801993-b74b-4417-bf15-cc172dabfa4c",
   "metadata": {},
   "source": [
    "#### Temperature = 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b21714-8092-4e9e-b66c-70258b1a8a4d",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf988fb3-a6ab-490b-a791-0c74a7f13aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3d55f639664cf8852fc069dbc6cea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d476545-88e0-4676-b774-05a96b82af9f",
   "metadata": {},
   "source": [
    "##### store responses and manually add gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07a7b652-8e9c-4498-bc80-4968374980c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df.write_csv(data_dir+'gpt3_responses.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d8a63-d4ea-48a1-bace-de92e162ef32",
   "metadata": {},
   "source": [
    "##### load responses with gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c35eaa3-eb2e-498c-b725-5cb8efe79691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>contains_sports_metaphor</th><th>sports_meta</th><th>explanation</th><th>ground_truth</th><th>post</th></tr><tr><td>str</td><td>bool</td><td>str</td><td>str</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;6ndhz6&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Surprise! Wome…</td></tr><tr><td>&quot;5zopk8&quot;</td><td>true</td><td>&quot;flex its muscl…</td><td>&quot;Assert authori…</td><td>true</td><td>&quot;Graham: Congre…</td></tr><tr><td>&quot;6a8vgu&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Trump Removes …</td></tr><tr><td>&quot;8vllco&quot;</td><td>true</td><td>&quot;set his sights…</td><td>&quot;Targeting or f…</td><td>true</td><td>&quot;Fired FBI Dire…</td></tr><tr><td>&quot;e6nbyn&quot;</td><td>false</td><td>null</td><td>null</td><td>false</td><td>&quot;Done deal: Cal…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────┬──────────────────┬──────────────────┬──────────────────┬──────────────┬─────────────────┐\n",
       "│ id     ┆ contains_sports_ ┆ sports_meta      ┆ explanation      ┆ ground_truth ┆ post            │\n",
       "│ ---    ┆ metaphor         ┆ ---              ┆ ---              ┆ ---          ┆ ---             │\n",
       "│ str    ┆ ---              ┆ str              ┆ str              ┆ bool         ┆ str             │\n",
       "│        ┆ bool             ┆                  ┆                  ┆              ┆                 │\n",
       "╞════════╪══════════════════╪══════════════════╪══════════════════╪══════════════╪═════════════════╡\n",
       "│ 6ndhz6 ┆ false            ┆ null             ┆ null             ┆ false        ┆ Surprise!       │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Women's         │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Marchers Hired… │\n",
       "│ 5zopk8 ┆ true             ┆ flex its muscle  ┆ Assert authority ┆ true         ┆ Graham:         │\n",
       "│        ┆                  ┆                  ┆ or power         ┆              ┆ Congress to     │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ ‘flex its mu…   │\n",
       "│ 6a8vgu ┆ false            ┆ null             ┆ null             ┆ false        ┆ Trump Removes   │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ FBI Director    │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ James…          │\n",
       "│ 8vllco ┆ true             ┆ set his sights   ┆ Targeting or     ┆ true         ┆ Fired FBI       │\n",
       "│        ┆                  ┆ on               ┆ focusing on a    ┆              ┆ Director James  │\n",
       "│        ┆                  ┆                  ┆ speci…           ┆              ┆ Comey s…        │\n",
       "│ e6nbyn ┆ false            ┆ null             ┆ null             ┆ false        ┆ Done deal:      │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ Calgary         │\n",
       "│        ┆                  ┆                  ┆                  ┆              ┆ taxpayers are…  │\n",
       "└────────┴──────────────────┴──────────────────┴──────────────────┴──────────────┴─────────────────┘"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "responses_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a784f5-8b22-4075-b3b6-353ffd4d75cb",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5b6b0-9ad5-4ca7-ab9f-35cd5da8d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()\n",
    "gt = responses_df['ground_truth'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ab66b-fea5-4754-bc8b-16317ae36e98",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b50203d2-609a-44be-90cf-829bc86210cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 170\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ba574-1a66-402f-9b3a-2c51c868dfc3",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "13a00bb4-d4b7-4aeb-9f2c-f0cae4720e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 51\n",
      "fp rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28de756-0074-4d08-abf8-79cd63c82c5b",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10904b9d-89f6-45e0-ae16-99e94ac6a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 27\n",
      "fn rate: 0.11688311688311688\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0e48c-c480-4807-820e-c467eb93fcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65d4c20-ade9-4fa2-b729-b9502e5ebf9a",
   "metadata": {},
   "source": [
    "#### Temperature = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e665ef-f777-4cdb-ad8f-2db30375147b",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f6e4bfd1-2092-4f8e-87cb-76a409831c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a8249eadfd4b43a042e788b8741c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.50\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895fe98-9629-4ea8-939d-aa6d4d7602c9",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20fa3d0e-2e51-449b-ba20-0b71fb0b9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423079a3-2bc9-479b-9d0c-b692394eb79a",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36d27d02-3639-487b-8553-e18d5443ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e39213-0222-4a1e-96ef-1d79893ae4af",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c8e67b26-c53a-41dc-bcbe-26d725b9e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561a859-94f2-4cf8-b0d3-2577b910e41a",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c98e787b-41b7-49c8-9a4f-dfcff435b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 168\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbe06c-feee-4c1d-b578-6c0fb2fda8c8",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69c13748-5f4b-413a-851c-b975fb1c23e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 53\n",
      "fp rate: 0.31547619047619047\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f58f1-a30d-4a17-929f-eb82138c685f",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89cd46c6-93d0-4656-9d85-394b7cca21ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 31\n",
      "fn rate: 0.13304721030042918\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d82fb-d21d-49f5-86e7-e91ac77ed7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73a3e752-4e70-48c2-a64b-7f8dfdf21072",
   "metadata": {},
   "source": [
    "#### Temperature = 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fd5e0-3261-4223-82f8-fec97b843497",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52a62d14-7173-4da7-a106-29d421f1efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e597c52aae34c97a6a9587a9939cef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.45\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ee191-ab3b-4e55-8779-5532ef404227",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "238aaf82-3d60-4cab-b834-0e459a1788a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efeb86-1af4-4dfc-a43f-8df70d745ca7",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51ac4244-e47e-41f4-9edd-693b9d53cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef5e16-eba6-429c-a49f-678ec4fe2443",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2ee33c3-a0db-4177-b161-e1f0613786db",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbbfa6-7ab6-4174-86f1-55e66606975e",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e447b87-ace2-4bbe-bccc-3ea9d802bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 170\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d4ad5-17f9-4073-a001-582e56bfd65b",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9cb013c1-9b29-45a9-8b15-ff2e0174ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 51\n",
      "fp rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af957694-e266-4a30-8310-c7ded497f3c2",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ba2904ee-d3b9-4acd-97d4-90c2333c627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 27\n",
      "fn rate: 0.11688311688311688\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec5b95-eec9-4c56-9f16-6ccc702d02e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de85b16e-a921-4036-8492-595ff67f6271",
   "metadata": {},
   "source": [
    "#### Temperature = 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7642cd95-1510-43d3-acf4-76c7526e1163",
   "metadata": {},
   "source": [
    "##### load data and run chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a6708bd-ec16-440b-b0a7-7657d70ceedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cb6caaad1d401da77ff47201070315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.60\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'chatgpt_samples.csv')\n",
    "\n",
    "posts = samples_df['title'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Note that sports related words may be used in a nonmetaphorical way, do not label such cases as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2980a47-14cc-457b-90d6-f48b8d166dcb",
   "metadata": {},
   "source": [
    "##### save responses into df and remove one empty post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b7837a2-3d0a-4e14-b554-572be932984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)\n",
    "responses_df = responses_df.filter(~pl.col('post').is_in(['[deleted by user]']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6917ea9-00d6-49d1-b24d-984a9c496fdb",
   "metadata": {},
   "source": [
    "##### add gt to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9abcf77d-b368-420e-9d52-c01dd21622fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = responses_df.with_columns(pl.Series(name=\"ground_truth\", values=gt)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720743f-a1e5-47d7-b108-1adc07ff1a12",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4ba35751-7a4a-4fd0-aa34-7551c2eefc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190287bc-80d6-46bf-ae8d-7e110f47d787",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "29892b75-3e3b-4de2-b8cc-cf333bdf2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 177\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f69ac5-9401-4473-aae4-6d8ca976d3e7",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a69ef005-2a51-4e18-8c04-0d02e5dbac0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 56\n",
      "fp rate: 0.3163841807909605\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc3a04-19b0-4803-ada7-1d7b924135b9",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "218f80f2-0458-4ac6-8234-27a0d27e132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 25\n",
      "fn rate: 0.11160714285714286\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee63c2f-16f8-4f6b-83bf-a61635786413",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "07c8bf15-d190-486f-b632-00b6e22a5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_6.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a648b-4c10-4f22-b989-d7bc21582b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2862324c-293c-4d1b-9e27-190200fc9a20",
   "metadata": {},
   "source": [
    "#### New prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b81b6e1-f26b-47cc-9e03-ebdb55f6ed1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5f9d94d3814cdaad015e6f81b6c943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports metaphor or not. Do not identify sports related words or phrases used in the literal sense as sports metaphors. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150b3c9-c08e-4b3d-8e4b-4a17a69cc998",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ea8c5b-7cc1-48ad-823c-a6d2b95c46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24820931-df3f-435c-9e78-07b38cdcdb6a",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90fd24f9-5eed-438f-a194-bb0cd27ea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d828ee-c9dc-41bb-b44c-9c31bd145886",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b12c7e20-a569-4665-9196-089b26b7b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 147\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e209343-61c2-4945-8e15-bf0f090e2c04",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f4ef631-c9f6-4ebd-bd1e-d16069eca6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 40\n",
      "fp rate: 0.272108843537415\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c20ef-f0f3-40f9-9968-f9bde58f30ee",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd5071b7-2ca3-4dc2-85c5-75cfb668256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 39\n",
      "fn rate: 0.15354330708661418\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832df7e-fd64-48f3-ae57-06cbe5cdd8b9",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5645a25-fc8e-4237-8d89-323ce20009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_new_prompt.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6d366-f07a-4673-87b4-429c6e5b508b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eddf8b1f-0a21-4384-a841-d576a97b9248",
   "metadata": {},
   "source": [
    "#### sports related prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31963e25-0794-43ac-9ddd-afb69f23b744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86a0cf1ef504bca978cdc2f0ef0e278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title, and your task is to identify if the post contains a sports or sports related metaphor or not. Do not identify sports related words or phrases used in the literal sense as sports metaphors. If the text does contain a sports or sports related metaphor, identify the sports or sports related metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c58b9-40dc-4124-a2d8-c37be2c8fd6d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a6c89a-78f0-4d2f-bc1f-8f289fd7def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed155c-6873-4d9b-b28d-64040ae26354",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc572def-85ae-423e-bc4f-22df23eff5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4baa9-8ff4-4f3d-8061-5d5e2448c159",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphors by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2adad5d-e5fd-42b4-b8c2-c1b484c38073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 119\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e33ef3e-e4ef-4737-a9c4-3db24ce7426e",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0043eac-0bc3-4b35-835d-2c1b61347faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 31\n",
      "fp rate: 0.2605042016806723\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed8f61-d065-4fe7-bb24-e251ec1c29d0",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94d10744-1f8f-4515-acb0-062762ec5f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 58\n",
      "fn rate: 0.20567375886524822\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ac8d0-7fef-498b-95c8-2d4c6258c0a5",
   "metadata": {},
   "source": [
    "##### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fc40ae5-0ee9-4987-a063-32ed6474f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.write_csv(data_dir+'gpt3_responses_with_gt_sports_rel_prompt.csv', separator=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20327da7-479f-4f32-b49e-c32817119858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the post contains a sports metaphor or not.\n",
    "# Do not identify sports related words or phrases used in the literal sense as sports metaphors.\n",
    "# If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e75839-faeb-4902-ae88-245e787c124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 2\n",
    "\n",
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the post contains a sports metaphor or not.\n",
    "# If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3ab67-c10b-4620-8292-8cc1ad469cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 3\n",
    "\n",
    "# You will be provided with a Reddit post title.\n",
    "# Identify if the title is framed using sports language or not.\n",
    "# If the title is framed using sports language, identify the title and provide a max 10 word explanation.\n",
    "# Provide the answer in a JSON format with the following keys, contains_sports_language (true/false), explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af7906-d876-45d2-8895-78a1fd96f292",
   "metadata": {},
   "source": [
    "#### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0ac978-4418-4fd4-aeed-4f56b8a4c843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b4b0468eb474ca3ec299c7a16e14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title. Identify if the post contains a sports metaphor or not. If the text does contain a sports metaphor, identify the sports metaphor word or phrase and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_metaphor (true/false), sports_metaphor, explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e384d-6e85-445c-b7e8-13fd61ebb5ab",
   "metadata": {},
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be11ef9f-69e0-4db7-98b3-1dbd589be252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_metaphor': [r['contains_sports_metaphor'] for r in all_responses],\n",
    "    'sports_meta': [r['sports_metaphor'] if 'sports_metaphor' in r else '' for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbf6d8-47de-401c-9f0e-db33abd8ab05",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00df4eb9-0774-47f3-9ac8-8fbd53249310",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_metaphor'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc200bf7-a5ae-4a7f-8cb9-88e1e8eed43d",
   "metadata": {},
   "source": [
    "##### total posts marked as sports metaphor by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0b7596-0b55-44b7-a6ba-c60bf9e7d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 155\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3850e8a-eb64-4d3d-b435-056aa89276b3",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd3d234-5886-42cd-8b40-810d5e4be816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 45\n",
      "fp rate: 0.2903225806451613\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2828ef-a711-4a8b-8552-98074326be2f",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764cee1a-91f3-41b1-9cab-7cfe88c90e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 36\n",
      "fn rate: 0.14634146341463414\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82125e-a13f-4e18-9bbe-87c671aed85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56d71d8b-e2ed-4637-a51a-7cbce1970bc3",
   "metadata": {},
   "source": [
    "#### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f55077-7d35-4a8b-b8a1-5b142485b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458ece7cae94c7b8b54c446f1624f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = 0.53\n",
    "all_responses = []\n",
    "\n",
    "samples_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "\n",
    "posts = samples_df['post'].to_list()\n",
    "ids = samples_df['id'].to_list()\n",
    "gt = samples_df['ground_truth'].to_list()\n",
    "\n",
    "bar = tqdm(range(len(posts)))\n",
    "for post in posts:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        seed=20,\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a Reddit post title. Identify if the title is framed using sports language or not. If the title is framed using sports language, identify the title and provide a max 10 word explanation. Provide the answer in a JSON format with the following keys, contains_sports_language (true/false), explanation.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": post\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "                \n",
    "    obj = json.loads(response.json())\n",
    "    resp_json = json.loads(obj[\"choices\"][0][\"message\"][\"content\"])\n",
    "    resp_json[\"post\"] = post\n",
    "    all_responses.append(resp_json)\n",
    "    bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb572f-9f9c-4459-b8ed-20fecdf6c6d9",
   "metadata": {},
   "source": [
    "##### save responses into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c9ad27-83ce-4ae5-9555-a1e5a486ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'id': ids,\n",
    "    'contains_sports_language': [r['contains_sports_language'] for r in all_responses],\n",
    "    'explanation': [r['explanation'] if 'explanation' in r else '' for r in all_responses],\n",
    "    'post': posts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "responses_df = pl.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d385e-c1b6-49f5-8c22-1c624e921e70",
   "metadata": {},
   "source": [
    "##### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26503e37-1553-46d3-b4c3-1537591cb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = responses_df['contains_sports_language'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa2dee-0e7c-400e-ba3c-a99f8a9223f7",
   "metadata": {},
   "source": [
    "##### total posts marked as sports language by gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a62a30d-af11-4f16-a881-5ad58519b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by gpt: 21\n"
     ]
    }
   ],
   "source": [
    "gpt_pos = 0\n",
    "for val in gpt_output:\n",
    "    if val:\n",
    "        gpt_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by gpt: {}'.format(gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4dff5-6019-4c14-939c-c769fb06a5bf",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac040c5-38fa-46cc-9285-b5c76a708da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 10\n",
      "fp rate: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if gpt_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/gpt_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebbbe6-728e-454e-af1d-2f712bfd2ed9",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f15e3d73-a90e-4f9d-8fb3-95aaf0c599bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 135\n",
      "fn rate: 0.35526315789473684\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(gpt_output)):\n",
    "    if not gpt_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-gpt_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660720c1-8ce8-4c03-a2eb-0f652d7cabc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a802182-3c50-4706-a200-d5a2936ed506",
   "metadata": {},
   "source": [
    "#### Sem matching (no FrameBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e63a8c7-573c-405f-94cf-0771d4d907d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>post</th><th>ground_truth</th><th>result</th><th>sports_meta</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;6ndhz6&quot;</td><td>&quot;surprise women…</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;5zopk8&quot;</td><td>&quot;graham congres…</td><td>true</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;6a8vgu&quot;</td><td>&quot;trump removes …</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;8vllco&quot;</td><td>&quot;fired fbi dire…</td><td>true</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;e6nbyn&quot;</td><td>&quot;done deal calg…</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬───────────────────────────────────┬──────────────┬────────┬─────────────┐\n",
       "│ id     ┆ post                              ┆ ground_truth ┆ result ┆ sports_meta │\n",
       "│ ---    ┆ ---                               ┆ ---          ┆ ---    ┆ ---         │\n",
       "│ str    ┆ str                               ┆ bool         ┆ bool   ┆ str         │\n",
       "╞════════╪═══════════════════════════════════╪══════════════╪════════╪═════════════╡\n",
       "│ 6ndhz6 ┆ surprise womens marchers hired a… ┆ false        ┆ false  ┆             │\n",
       "│ 5zopk8 ┆ graham congress to flex its musc… ┆ true         ┆ false  ┆             │\n",
       "│ 6a8vgu ┆ trump removes fbi director james… ┆ false        ┆ false  ┆             │\n",
       "│ 8vllco ┆ fired fbi director james comey s… ┆ true         ┆ false  ┆             │\n",
       "│ e6nbyn ┆ done deal calgary taxpayers are … ┆ false        ┆ false  ┆             │\n",
       "└────────┴───────────────────────────────────┴──────────────┴────────┴─────────────┘"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_df = pl.read_csv(data_dir+'sem_matching_responses_eval.csv')\n",
    "sem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53d2cdec-01a3-4c2a-b96d-47c91c2f1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_output = sem_df['result'].to_list()\n",
    "gt = sem_df['ground_truth'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "433f4544-5276-49cc-a347-24b154a69770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total posts marked as sports metaphors by sem matching: 47\n"
     ]
    }
   ],
   "source": [
    "sem_pos = 0\n",
    "for val in sem_output:\n",
    "    if val:\n",
    "        sem_pos += 1\n",
    "\n",
    "print('total posts marked as sports metaphors by sem matching: {}'.format(sem_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedf0ee-9c2d-4685-9f17-92d192ea285f",
   "metadata": {},
   "source": [
    "##### false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c13ce5da-069a-40df-901e-65dda88846db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fp: 12\n",
      "fp rate: 0.2553191489361702\n"
     ]
    }
   ],
   "source": [
    "fp = 0\n",
    "for i in range(len(sem_output)):\n",
    "    if sem_output[i] and not gt[i]:\n",
    "        fp += 1\n",
    "\n",
    "print('total fp: {}'.format(fp))\n",
    "print('fp rate: {}'.format(fp/sem_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be7d933-99de-414a-9979-2d5ec29ca4be",
   "metadata": {},
   "source": [
    "##### false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eca9fbd0-732a-4b57-9968-6eafe7e962e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fn: 111\n",
      "fn rate: 0.3135593220338983\n"
     ]
    }
   ],
   "source": [
    "fn = 0\n",
    "for i in range(len(sem_output)):\n",
    "    if not sem_output[i] and gt[i]:\n",
    "        fn += 1\n",
    "\n",
    "print('total fn: {}'.format(fn))\n",
    "print('fn rate: {}'.format(fn/(len(gt)-sem_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68925d04-f7ec-4ae5-9711-290965a939d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb57b9bf-7af9-474c-8385-7bd76032c878",
   "metadata": {},
   "source": [
    "#### FrameBERT filter on chatgpt output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b45071-d734-4cdf-b4f1-65095ee9911b",
   "metadata": {},
   "source": [
    "##### temp = 0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21a1d6e1-1064-4731-b5d9-a59b52274d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pl.read_csv(data_dir+'gpt3_responses_with_gt_53.csv')\n",
    "frame_df = pl.read_csv(data_dir+'sample_predictions_gpt_53.tsv', separator='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03306a11-d16f-458d-bf62-1c573ffa205f",
   "metadata": {},
   "source": [
    "##### get unigram metaphors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163a6f7-c204-4548-9b5c-b66a0c3146ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_META_LIST = ['out', 'up', 'tip', 'check']\n",
    "\n",
    "with open(data_dir+'meta_dict_full.json', 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "meta_list = []\n",
    "for key, values in data.items():\n",
    "    meta_list.extend(values)\n",
    "# remove duplicates\n",
    "meta_list = list(set(meta_list))\n",
    "# filter metaphors\n",
    "meta_list = [meta.replace(\"'\", '') for meta in meta_list]\n",
    "meta_list = [re.sub(r\"[^a-zA-Z0-9]+\", ' ', meta).lower() for meta in meta_list]\n",
    "meta_list = [m for m in meta_list if m not in NO_META_LIST]\n",
    "\n",
    "uni_metas = []\n",
    "\n",
    "for meta in meta_list:\n",
    "    if len(meta.split()) == 1:\n",
    "        uni_metas.append(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d23ee6-50fa-4c71-8b04-90d04fbff971",
   "metadata": {},
   "source": [
    "##### get posts with unigram metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efbf8939-cf5a-44ad-9893-d580cf6baa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>contains_sports_metaphor</th><th>sports_meta</th><th>explanation</th><th>ground_truth</th><th>post</th></tr><tr><td>str</td><td>bool</td><td>str</td><td>str</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;jmgevc&quot;</td><td>true</td><td>&quot;underdog&quot;</td><td>&quot;refers to a te…</td><td>true</td><td>&quot;FiveThirtyEigh…</td></tr><tr><td>&quot;3uww8c&quot;</td><td>true</td><td>&quot;game&quot;</td><td>&quot;Refers to the …</td><td>true</td><td>&quot;Russia hits ba…</td></tr><tr><td>&quot;39cs9k&quot;</td><td>true</td><td>&quot;underdog&quot;</td><td>&quot;Referring to a…</td><td>true</td><td>&quot;Bernie Sanders…</td></tr><tr><td>&quot;cm0qti&quot;</td><td>true</td><td>&quot;punt&quot;</td><td>&quot;Avoiding addre…</td><td>true</td><td>&quot;Texas GOPers P…</td></tr><tr><td>&quot;2talrj&quot;</td><td>true</td><td>&quot;outfox&quot;</td><td>&quot;To outsmart or…</td><td>true</td><td>&quot;Republicans ou…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌────────┬────────────────────┬─────────────┬───────────────────┬──────────────┬───────────────────┐\n",
       "│ id     ┆ contains_sports_me ┆ sports_meta ┆ explanation       ┆ ground_truth ┆ post              │\n",
       "│ ---    ┆ taphor             ┆ ---         ┆ ---               ┆ ---          ┆ ---               │\n",
       "│ str    ┆ ---                ┆ str         ┆ str               ┆ bool         ┆ str               │\n",
       "│        ┆ bool               ┆             ┆                   ┆              ┆                   │\n",
       "╞════════╪════════════════════╪═════════════╪═══════════════════╪══════════════╪═══════════════════╡\n",
       "│ jmgevc ┆ true               ┆ underdog    ┆ refers to a team  ┆ true         ┆ FiveThirtyEight   │\n",
       "│        ┆                    ┆             ┆ or player not f…  ┆              ┆ founder Nate Sil… │\n",
       "│ 3uww8c ┆ true               ┆ game        ┆ Refers to the     ┆ true         ┆ Russia hits back  │\n",
       "│        ┆                    ┆             ┆ situation or      ┆              ┆ at Turkey by ch…  │\n",
       "│        ┆                    ┆             ┆ confl…            ┆              ┆                   │\n",
       "│ 39cs9k ┆ true               ┆ underdog    ┆ Referring to a    ┆ true         ┆ Bernie Sanders:   │\n",
       "│        ┆                    ┆             ┆ team or player    ┆              ┆ 'We Are The Unde… │\n",
       "│        ┆                    ┆             ┆ no…               ┆              ┆                   │\n",
       "│ cm0qti ┆ true               ┆ punt        ┆ Avoiding          ┆ true         ┆ Texas GOPers Punt │\n",
       "│        ┆                    ┆             ┆ addressing the    ┆              ┆ On Gun Control…   │\n",
       "│        ┆                    ┆             ┆ issue or…         ┆              ┆                   │\n",
       "│ 2talrj ┆ true               ┆ outfox      ┆ To outsmart or    ┆ true         ┆ Republicans       │\n",
       "│        ┆                    ┆             ┆ outwit the        ┆              ┆ outfox Democrats  │\n",
       "│        ┆                    ┆             ┆ oppone…           ┆              ┆ on …              │\n",
       "└────────┴────────────────────┴─────────────┴───────────────────┴──────────────┴───────────────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_meta_df = responses_df.filter(pl.col('sports_meta').is_in(uni_metas))\n",
    "uni_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f707961-8822-4323-96aa-efac0ba444a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c86a47-53fb-4682-9118-966d170724ca",
   "metadata": {},
   "source": [
    "#### FrameBERT filter on sem matching output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12cdfd0d-eb04-496f-8325-358d0f2fc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_df = pl.read_csv(data_dir+'sem_matching_responses_eval.csv')\n",
    "frame_df = pl.read_csv(data_dir+'sample_predictions_sem_match.tsv', separator='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdd023-e786-46bf-91b8-c26b9bb19847",
   "metadata": {},
   "source": [
    "##### get unigram metaphors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3948957-9c6c-4261-93d1-9f53dbd3219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_META_LIST = ['out', 'up', 'tip', 'check']\n",
    "\n",
    "with open(data_dir+'meta_dict_full.json', 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "meta_list = []\n",
    "for key, values in data.items():\n",
    "    meta_list.extend(values)\n",
    "# remove duplicates\n",
    "meta_list = list(set(meta_list))\n",
    "# filter metaphors\n",
    "meta_list = [meta.replace(\"'\", '') for meta in meta_list]\n",
    "meta_list = [re.sub(r\"[^a-zA-Z0-9]+\", ' ', meta).lower() for meta in meta_list]\n",
    "meta_list = [m for m in meta_list if m not in NO_META_LIST]\n",
    "\n",
    "uni_metas = []\n",
    "\n",
    "for meta in meta_list:\n",
    "    if len(meta.split()) == 1:\n",
    "        uni_metas.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fff16ec8-1fac-4fd8-a750-d497d346f8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>post</th><th>ground_truth</th><th>result</th><th>sports_meta</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;6ndhz6&quot;</td><td>&quot;surprise women…</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;5zopk8&quot;</td><td>&quot;graham congres…</td><td>true</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;6a8vgu&quot;</td><td>&quot;trump removes …</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;8vllco&quot;</td><td>&quot;fired fbi dire…</td><td>true</td><td>false</td><td>&quot;&quot;</td></tr><tr><td>&quot;e6nbyn&quot;</td><td>&quot;done deal calg…</td><td>false</td><td>false</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬───────────────────────────────────┬──────────────┬────────┬─────────────┐\n",
       "│ id     ┆ post                              ┆ ground_truth ┆ result ┆ sports_meta │\n",
       "│ ---    ┆ ---                               ┆ ---          ┆ ---    ┆ ---         │\n",
       "│ str    ┆ str                               ┆ bool         ┆ bool   ┆ str         │\n",
       "╞════════╪═══════════════════════════════════╪══════════════╪════════╪═════════════╡\n",
       "│ 6ndhz6 ┆ surprise womens marchers hired a… ┆ false        ┆ false  ┆             │\n",
       "│ 5zopk8 ┆ graham congress to flex its musc… ┆ true         ┆ false  ┆             │\n",
       "│ 6a8vgu ┆ trump removes fbi director james… ┆ false        ┆ false  ┆             │\n",
       "│ 8vllco ┆ fired fbi director james comey s… ┆ true         ┆ false  ┆             │\n",
       "│ e6nbyn ┆ done deal calgary taxpayers are … ┆ false        ┆ false  ┆             │\n",
       "└────────┴───────────────────────────────────┴──────────────┴────────┴─────────────┘"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143ef29-5d50-425b-8a15-324c4a0e1946",
   "metadata": {},
   "source": [
    "##### get posts with unigram metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a68b5d41-2952-4990-982c-bcaef7493df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>post</th><th>ground_truth</th><th>result</th><th>sports_meta</th></tr><tr><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;h93utk&quot;</td><td>&quot;economy is off…</td><td>true</td><td>true</td><td>&quot;off to the rac…</td></tr><tr><td>&quot;44z4w5&quot;</td><td>&quot;jeb bush gets …</td><td>false</td><td>true</td><td>&quot;bush&quot;</td></tr><tr><td>&quot;b5lx5v&quot;</td><td>&quot;trump and repu…</td><td>true</td><td>true</td><td>&quot;turn the table…</td></tr><tr><td>&quot;j06sti&quot;</td><td>&quot;activists to s…</td><td>true</td><td>true</td><td>&quot;play hardball&quot;</td></tr><tr><td>&quot;a962r0&quot;</td><td>&quot;the only probl…</td><td>true</td><td>true</td><td>&quot;score&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬───────────────────────────────────┬──────────────┬────────┬──────────────────┐\n",
       "│ id     ┆ post                              ┆ ground_truth ┆ result ┆ sports_meta      │\n",
       "│ ---    ┆ ---                               ┆ ---          ┆ ---    ┆ ---              │\n",
       "│ str    ┆ str                               ┆ bool         ┆ bool   ┆ str              │\n",
       "╞════════╪═══════════════════════════════════╪══════════════╪════════╪══════════════════╡\n",
       "│ h93utk ┆ economy is off to the races on v… ┆ true         ┆ true   ┆ off to the races │\n",
       "│ 44z4w5 ┆ jeb bush gets cut off by his own… ┆ false        ┆ true   ┆ bush             │\n",
       "│ b5lx5v ┆ trump and republicans seek to tu… ┆ true         ┆ true   ┆ turn the tables  │\n",
       "│ j06sti ┆ activists to senate democrats ti… ┆ true         ┆ true   ┆ play hardball    │\n",
       "│ a962r0 ┆ the only problem our economy has… ┆ true         ┆ true   ┆ score            │\n",
       "└────────┴───────────────────────────────────┴──────────────┴────────┴──────────────────┘"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_meta_df = sem_df.filter(pl.col('result'))\n",
    "uni_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f8d1f-6f0b-4619-b685-02f36e54547c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6931dc0d-36a3-4c80-a457-d91905e7c219",
   "metadata": {},
   "source": [
    "##### preprocess framebert output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32f4eead-8064-4ed6-a646-509c50eaedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_df = frame_df.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "892ea608-5a38-4f40-814d-f9c6b47b70c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Tokens</th><th>Borderline_metaphor</th><th>Real_metaphors</th><th>Frame_label</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;surprise&quot;</td><td>0</td><td>0</td><td>&quot;Experiencer_ob…</td></tr><tr><td>&quot;womens&quot;</td><td>0</td><td>0</td><td>&quot;_&quot;</td></tr><tr><td>&quot;marchers&quot;</td><td>0</td><td>0</td><td>&quot;Change_of_lead…</td></tr><tr><td>&quot;hired&quot;</td><td>0</td><td>0</td><td>&quot;Hiring&quot;</td></tr><tr><td>&quot;armed&quot;</td><td>0</td><td>0</td><td>&quot;Bearing_arms&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────┬─────────────────────┬────────────────┬──────────────────────┐\n",
       "│ Tokens   ┆ Borderline_metaphor ┆ Real_metaphors ┆ Frame_label          │\n",
       "│ ---      ┆ ---                 ┆ ---            ┆ ---                  │\n",
       "│ str      ┆ i64                 ┆ i64            ┆ str                  │\n",
       "╞══════════╪═════════════════════╪════════════════╪══════════════════════╡\n",
       "│ surprise ┆ 0                   ┆ 0              ┆ Experiencer_obj      │\n",
       "│ womens   ┆ 0                   ┆ 0              ┆ _                    │\n",
       "│ marchers ┆ 0                   ┆ 0              ┆ Change_of_leadership │\n",
       "│ hired    ┆ 0                   ┆ 0              ┆ Hiring               │\n",
       "│ armed    ┆ 0                   ┆ 0              ┆ Bearing_arms         │\n",
       "└──────────┴─────────────────────┴────────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aa33740d-346f-4575-a5ab-ed0e179e960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>post</th><th>gen_meta</th><th>frame</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;surprise women…</td><td>null</td><td>null</td></tr><tr><td>&quot;graham congres…</td><td>&quot;flex, muscle, …</td><td>&quot;Manipulation, …</td></tr><tr><td>&quot;trump removes …</td><td>&quot;removes&quot;</td><td>&quot;Removing&quot;</td></tr><tr><td>&quot;fired fbi dire…</td><td>&quot;sights&quot;</td><td>&quot;_&quot;</td></tr><tr><td>&quot;done deal calg…</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────────────────────────────────┬────────────────────┬───────────────────────────────────┐\n",
       "│ post                              ┆ gen_meta           ┆ frame                             │\n",
       "│ ---                               ┆ ---                ┆ ---                               │\n",
       "│ str                               ┆ str                ┆ str                               │\n",
       "╞═══════════════════════════════════╪════════════════════╪═══════════════════════════════════╡\n",
       "│ surprise womens marchers hired a… ┆ null               ┆ null                              │\n",
       "│ graham congress to flex its musc… ┆ flex, muscle, ties ┆ Manipulation, Body_parts, Social… │\n",
       "│ trump removes fbi director james… ┆ removes            ┆ Removing                          │\n",
       "│ fired fbi director james comey s… ┆ sights             ┆ _                                 │\n",
       "│ done deal calgary taxpayers are … ┆ null               ┆ null                              │\n",
       "└───────────────────────────────────┴────────────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = frame_df['Tokens'].to_list()\n",
    "metas = frame_df['Real_metaphors'].to_list()\n",
    "frames = frame_df['Frame_label'].to_list()\n",
    "\n",
    "posts = []\n",
    "gen_meta = []\n",
    "frame_label = []\n",
    "\n",
    "sen = []\n",
    "meta = []\n",
    "frame = []\n",
    "for t in range(len(tokens)):\n",
    "    sen.append(tokens[t])\n",
    "    if metas[t] == 1:\n",
    "        meta.append(tokens[t])\n",
    "        frame.append(frames[t])\n",
    "    if tokens[t] == '.':\n",
    "        post = \" \".join(sen)\n",
    "        posts.append(post)\n",
    "        sen = []\n",
    "        if len(meta) > 1:\n",
    "            gen_meta.append(', '.join(meta))\n",
    "            frame_label.append(', '.join(frame))\n",
    "        elif len(meta) == 1:\n",
    "            gen_meta.append(meta[0])\n",
    "            frame_label.append(frame[0])\n",
    "        else:\n",
    "            gen_meta.append(None)\n",
    "            frame_label.append(None)\n",
    "        meta = []\n",
    "        frame = []\n",
    "\n",
    "new_frame_df = pl.from_dict(\n",
    "    {\n",
    "        'post': posts,\n",
    "        'gen_meta': gen_meta,\n",
    "        'frame': frame_label,\n",
    "    }\n",
    ")\n",
    "\n",
    "new_frame_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c9ada623-0677-42c9-ade8-7ec88ad79c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_meta = []\n",
    "\n",
    "for item in gen_meta:\n",
    "    if item is not None:\n",
    "        metas = item.split(',')\n",
    "        val = False\n",
    "        for meta in metas:\n",
    "            if meta in uni_metas:\n",
    "                val = True\n",
    "                break\n",
    "        sports_meta.append(val)\n",
    "                \n",
    "    else:\n",
    "        sports_meta.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "81383564-e886-4439-844a-b203440d8fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sports_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5f566c2-7c17-4802-99e1-12d59fa39572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac064da-c172-4226-9ec1-26ae1141ff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
