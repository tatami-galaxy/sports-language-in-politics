{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57ce7f0-ace6-417a-a664-8eaa757287b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from os.path import dirname, abspath\n",
    "from functools import partial\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ecf1bf-8cb0-404e-9e3c-cfc382c72ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIMENSION = 300\n",
    "EMBED_MAX_NORM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d5db6a-cff9-4938-8ff6-024e9d8feeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/users/ujan/sports-language-in-politics/data/processed/the_donald_bert_embed.json\") as f:\n",
    "    bert_embed = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7502800-de60-4053-86bb-0252a6c2d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_vocab(embed):\n",
    "    \n",
    "    vocab = list(embed.keys())\n",
    "    print('vocab size: {}'.format(len(vocab)))\n",
    "\n",
    "    def normalization(embeddings):\n",
    "        norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
    "        norms = np.reshape(norms, (len(norms), 1))\n",
    "        embeddings_norm = embeddings / norms\n",
    "        return embeddings_norm\n",
    "    \n",
    "    embed_list = []\n",
    "    for word in vocab:\n",
    "        embed_list.append(embed[word])\n",
    "    embeddings = np.array(embed_list)\n",
    "    \n",
    "    # normalization\n",
    "    embeddings_norm = normalization(embeddings)\n",
    "\n",
    "    return embeddings_norm, embed\n",
    "\n",
    "\n",
    "def get_top_similar(word: str, embeddings_norm, vocab, topN: int=5):\n",
    "    if word not in vocab:\n",
    "        print(\"Out of vocabulary word\")\n",
    "        return\n",
    "    vocab_list = list(vocab.keys())\n",
    "    q_id = vocab_list.index(word)\n",
    "    word_vec = embeddings_norm[q_id]\n",
    "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
    "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
    "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
    "    print(topN_ids)\n",
    "\n",
    "    topN_dict = {}\n",
    "    for sim_word_id in topN_ids:\n",
    "        sim_word = vocab_list[sim_word_id]\n",
    "        topN_dict[sim_word] = dists[sim_word_id]\n",
    "    return topN_dict\n",
    "    \n",
    "\n",
    "def get_analogy(a,b,c, embeddings_norm, vocab):\n",
    "    vocab_list = list(vocab.keys())\n",
    "    if a not in vocab_list or b not in vocab_list or c not in vocab_list:\n",
    "        print('not in vocab')\n",
    "        return\n",
    "    a_id = vocab_list.index(a)\n",
    "    b_id = vocab_list.index(b)\n",
    "    c_id = vocab_list.index(c)\n",
    "\n",
    "    a_vec = embeddings_norm[a_id]\n",
    "    b_vec = embeddings_norm[b_id]\n",
    "    c_vec = embeddings_norm[c_id]\n",
    "    \n",
    "    sim = -2\n",
    "    target = None\n",
    "    sim_dict = {}\n",
    "    for token in vocab_list:\n",
    "        #if token in [a,b,c]:\n",
    "            #continue\n",
    "        token_vec = vocab[token]\n",
    "        s = np.dot(token_vec, b_vec-a_vec+c_vec)\n",
    "        if s > sim:\n",
    "            sim = s\n",
    "            target = token\n",
    "        if len(sim_dict) < 5:\n",
    "            sim_dict[token] = s\n",
    "        else:\n",
    "            min_key = min(sim_dict, key=sim_dict.get)\n",
    "            min_val = sim_dict[min_key]\n",
    "            if s > min_val:\n",
    "                del sim_dict[min_key]\n",
    "                sim_dict[token] = s\n",
    "                    \n",
    "    print(target, sim)\n",
    "    print(list(sim_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adcc0491-1522-418f-a099-29a1eef53544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 141315\n"
     ]
    }
   ],
   "source": [
    "embeddings_norm, vocab = get_embeddings_and_vocab(bert_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392cf2a-3fa6-46ad-be27-752a2574ab99",
   "metadata": {},
   "source": [
    "##### similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f94ba325-bcd8-4a42-9910-805d915aee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1489  1341 12215  6426  1340]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'yellow': 0.7891525729468087,\n",
       " 'blue': 0.7852215814655803,\n",
       " 'redzone': 0.7581747161029492,\n",
       " 'purple': 0.7456772740160242,\n",
       " 'green': 0.7396133718002599}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('red', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a9556e5-3da5-43fe-be63-5927109a06af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8243 24551 60487   537   770]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'captains': 0.8689232470403931,\n",
       " 'captaincy': 0.8382648958171743,\n",
       " 'captained': 0.752838344329176,\n",
       " 'player': 0.7472572215821804,\n",
       " 'leader': 0.7404562584459732}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('captain', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbe1baf6-8618-4cdf-a368-3e6a53902be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40103  10228 122133   1291  66016]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'busses': 0.8235935669807237,\n",
       " 'buses': 0.8126035558194924,\n",
       " 'busload': 0.7932670976685302,\n",
       " 'train': 0.7556962560867636,\n",
       " 'tram': 0.6987717388377841}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('bus', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d4ff3d-f868-4090-b08e-6077dde609ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7314  5833  2476 20818  4125]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'presidents': 0.8734757463719285,\n",
       " 'presidency': 0.869463995409985,\n",
       " 'presidential': 0.8367583351716343,\n",
       " 'presidental': 0.7933712318362054,\n",
       " 'administration': 0.7792574784366104}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('president', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "059feffb-52b1-47d2-8bba-c0401722ed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3071 60089 25266   666 55184]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'elections': 0.9072837601504775,\n",
       " 'electioneering': 0.8756772888097173,\n",
       " 'reelection': 0.8547783510794441,\n",
       " 'elected': 0.8392037156559514,\n",
       " 'electionday': 0.8272017592504846}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('election', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d64a5de-8033-401d-89d5-8d2d6ca1a5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4854  9223 26476 28426  1486]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'races': 0.872780962016001,\n",
       " 'racial': 0.8235731372009734,\n",
       " 'ethnicity': 0.7938107639573562,\n",
       " 'whiteness': 0.7535558855366566,\n",
       " 'color': 0.7503275426978833}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('race', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a94fff19-8933-43ad-b355-4649c56f2057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2201  2512  3061 32216 90886]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'voter': 0.8552195927212787,\n",
       " 'votes': 0.8437491481399981,\n",
       " 'voting': 0.8352483727434798,\n",
       " 'electorate': 0.8336844772137472,\n",
       " 'electorates': 0.8186677502996491}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_similar('voters', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f141ee-4445-4969-ba3d-b764e60a6835",
   "metadata": {},
   "source": [
    "##### analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac6ae680-0e5e-433a-b0d6-98a098ca1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen 9.460865361000687\n",
      "['woman', 'queen', 'princess', 'womanhood', 'queenie']\n"
     ]
    }
   ],
   "source": [
    "get_analogy('man', 'king', 'woman', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaafb954-f0c2-4d13-98d8-a517c335220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germany 10.45201836807469\n",
      "['german', 'germany', 'berlin', 'deutschland', 'prussia']\n"
     ]
    }
   ],
   "source": [
    "get_analogy('paris', 'france', 'berlin', embeddings_norm, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4e73bd4-d6fd-4b80-9b0a-0b2ecc85f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fine tune on data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
